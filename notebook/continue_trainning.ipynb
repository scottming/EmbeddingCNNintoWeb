{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('../py/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from text_cnn import TextCNN\n",
    "from text_helpers import (\n",
    "    build_dataset, clean_data, jieba_cut, load_dict, \n",
    "    pad_crop, read_stopwords, word_to_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "build_dataset??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_sample_to_sql(frac):\n",
    "    db = '../py/reviews.sqlite'\n",
    "    conn = sqlite3.connect(db)\n",
    "    now = datetime.datetime.now()\n",
    "    df = pd.read_csv('../data/test_shuffle.txt', names='review sentiment'.split(), sep='\\t')\n",
    "    df['date'] = now\n",
    "    sample_test = df.sample(frac=frac)\n",
    "    row_counts = sample_test.shape[0]\n",
    "    sample_test.to_sql('review_db', conn, if_exists='append', index=False)\n",
    "    conn.close()\n",
    "    print(f'Added {row_counts} records to review_db.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sqltext_to_number(\n",
    "        X, vocab2ix_path='../data/vocab2ix.pkl', \n",
    "        ix2vocab_path='../data/ix2vocab.pkl', \n",
    "        stopwords_path='../data/stop_words_chinese.txt', \n",
    "        max_words=20):\n",
    "    # Read dict and stopwords\n",
    "    vocab2ix, _ = load_dict(vocab2ix_path, ix2vocab_path)\n",
    "    stopwords = read_stopwords(stopwords_path)\n",
    "    # Clean data\n",
    "    data_cut = jieba_cut(X)\n",
    "    text_data = clean_data(data_cut, stopwords)\n",
    "    # Words to numbers\n",
    "    num_data = word_to_number(text_data, vocab2ix)\n",
    "    num_data_pad = list(pad_crop(num_data, max_words))\n",
    "    return np.asarray(num_data_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_continue_train_dataset(db_path, continue_train_size):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    c.execute('SELECT * FROM review_db ORDER BY date DESC')\n",
    "    results = c.fetchmany(continue_train_size)\n",
    "    data = np.array(results)\n",
    "    X = data[:, 0]\n",
    "    y = data[:, 1].astype(int)\n",
    "    x_train = sqltext_to_number(X)\n",
    "    conn.close()\n",
    "    return x_train, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_steps = 100\n",
    "print_loss_every = 2\n",
    "batch_size = 50\n",
    "keep_proba = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = np.loadtxt('../data/train_data.txt', dtype=int)\n",
    "test = np.loadtxt('../data/test_data.txt', dtype=int)\n",
    "x_train = train[:, :-1]\n",
    "y_train = train[:, -1:].reshape((-1,))\n",
    "x_test = test[:, :-1]\n",
    "y_test = test[:, -1:].reshape((-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们试着从测试数据里面随机挑选一部分数据，然后推送到数据库，看看 Online-Learning 对测试数据的意义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 11 records to review_db.\n"
     ]
    }
   ],
   "source": [
    "# add_sample_to_sql(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_con_train, y_con_train = get_continue_train_dataset('../py/reviews.sqlite', 10000)\n",
    "dataset_size = x_con_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous: Train/Test ACC: 0.953/0.869\n",
      "Epoch: 0000 | AvgCost:  0.8999 | Train/Test ACC: 0.955/0.874\n",
      "Epoch: 0002 | AvgCost:  0.5421 | Train/Test ACC: 0.959/0.880\n",
      "Epoch: 0004 | AvgCost:  0.7504 | Train/Test ACC: 0.959/0.880\n",
      "Epoch: 0006 | AvgCost:  1.1248 | Train/Test ACC: 0.959/0.881\n",
      "Epoch: 0008 | AvgCost:  0.4133 | Train/Test ACC: 0.959/0.882\n",
      "Epoch: 0010 | AvgCost:  0.5314 | Train/Test ACC: 0.959/0.882\n",
      "Epoch: 0012 | AvgCost:  0.6451 | Train/Test ACC: 0.958/0.881\n",
      "Epoch: 0014 | AvgCost:  0.4869 | Train/Test ACC: 0.958/0.882\n",
      "Epoch: 0016 | AvgCost:  1.7890 | Train/Test ACC: 0.957/0.882\n",
      "Epoch: 0018 | AvgCost:  0.3451 | Train/Test ACC: 0.957/0.880\n",
      "Epoch: 0020 | AvgCost:  0.6135 | Train/Test ACC: 0.957/0.881\n",
      "Epoch: 0022 | AvgCost:  0.7336 | Train/Test ACC: 0.957/0.881\n",
      "Epoch: 0024 | AvgCost:  0.2813 | Train/Test ACC: 0.956/0.881\n",
      "Epoch: 0026 | AvgCost:  0.4135 | Train/Test ACC: 0.956/0.880\n",
      "Epoch: 0028 | AvgCost:  0.3224 | Train/Test ACC: 0.955/0.879\n",
      "Epoch: 0030 | AvgCost:  0.3150 | Train/Test ACC: 0.955/0.879\n",
      "Epoch: 0032 | AvgCost:  0.6636 | Train/Test ACC: 0.956/0.879\n",
      "Epoch: 0034 | AvgCost:  0.2654 | Train/Test ACC: 0.955/0.879\n",
      "Epoch: 0036 | AvgCost:  0.4048 | Train/Test ACC: 0.955/0.879\n",
      "Epoch: 0038 | AvgCost:  0.6190 | Train/Test ACC: 0.954/0.877\n",
      "Epoch: 0040 | AvgCost:  0.4500 | Train/Test ACC: 0.954/0.877\n",
      "Epoch: 0042 | AvgCost:  0.5098 | Train/Test ACC: 0.953/0.876\n",
      "Epoch: 0044 | AvgCost:  0.2455 | Train/Test ACC: 0.954/0.876\n",
      "Epoch: 0046 | AvgCost:  0.7262 | Train/Test ACC: 0.953/0.876\n",
      "Epoch: 0048 | AvgCost:  0.2825 | Train/Test ACC: 0.953/0.876\n",
      "Epoch: 0050 | AvgCost:  0.2054 | Train/Test ACC: 0.953/0.876\n",
      "Epoch: 0052 | AvgCost:  0.4605 | Train/Test ACC: 0.952/0.874\n",
      "Epoch: 0054 | AvgCost:  0.2226 | Train/Test ACC: 0.951/0.874\n",
      "Epoch: 0056 | AvgCost:  0.3628 | Train/Test ACC: 0.951/0.873\n",
      "Epoch: 0058 | AvgCost:  0.5491 | Train/Test ACC: 0.952/0.873\n",
      "Epoch: 0060 | AvgCost:  0.1337 | Train/Test ACC: 0.952/0.874\n",
      "Epoch: 0062 | AvgCost:  0.3967 | Train/Test ACC: 0.951/0.874\n",
      "Epoch: 0064 | AvgCost:  0.3758 | Train/Test ACC: 0.950/0.873\n",
      "Epoch: 0066 | AvgCost:  0.3076 | Train/Test ACC: 0.951/0.874\n",
      "Epoch: 0068 | AvgCost:  0.7615 | Train/Test ACC: 0.951/0.874\n",
      "Epoch: 0070 | AvgCost:  0.1908 | Train/Test ACC: 0.952/0.874\n",
      "Epoch: 0072 | AvgCost:  0.5680 | Train/Test ACC: 0.952/0.876\n",
      "Epoch: 0074 | AvgCost:  0.5969 | Train/Test ACC: 0.953/0.875\n",
      "Epoch: 0076 | AvgCost:  0.0968 | Train/Test ACC: 0.954/0.876\n",
      "Epoch: 0078 | AvgCost:  0.4582 | Train/Test ACC: 0.954/0.878\n",
      "Epoch: 0080 | AvgCost:  0.3290 | Train/Test ACC: 0.954/0.877\n",
      "Epoch: 0082 | AvgCost:  0.3298 | Train/Test ACC: 0.955/0.877\n",
      "Epoch: 0084 | AvgCost:  0.4118 | Train/Test ACC: 0.954/0.877\n",
      "Epoch: 0086 | AvgCost:  0.2230 | Train/Test ACC: 0.954/0.877\n",
      "Epoch: 0088 | AvgCost:  0.4057 | Train/Test ACC: 0.954/0.878\n",
      "Epoch: 0090 | AvgCost:  0.4105 | Train/Test ACC: 0.954/0.877\n",
      "Epoch: 0092 | AvgCost:  0.2648 | Train/Test ACC: 0.954/0.877\n",
      "Epoch: 0094 | AvgCost:  0.3525 | Train/Test ACC: 0.954/0.877\n",
      "Epoch: 0096 | AvgCost:  0.1989 | Train/Test ACC: 0.954/0.878\n",
      "Epoch: 0098 | AvgCost:  0.2885 | Train/Test ACC: 0.955/0.878\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "graph = tf.Graph()\n",
    "with graph.as_default() as g:\n",
    "    with tf.Session(graph=g) as sess:\n",
    "        saver = tf.train.import_meta_graph('../save_model/model.ckpt.meta')\n",
    "        saver.restore(sess, '../save_model/model.ckpt')\n",
    "        input_x = graph.get_operation_by_name('input_x').outputs[0]\n",
    "        input_y = graph.get_operation_by_name('input_y').outputs[0]\n",
    "        keep_proba_ph = graph.get_operation_by_name('keep_proba').outputs[0]\n",
    "        accuracy = graph.get_operation_by_name('accuracy/accuracy').outputs[0]\n",
    "        loss = graph.get_operation_by_name('loss/loss').outputs[0]\n",
    "        \n",
    "        # Initialize opt variables\n",
    "        temp = set(tf.global_variables())\n",
    "        train_step = tf.train.AdamOptimizer(learning_rate, name='adam2').minimize(loss)\n",
    "        sess.run(tf.variables_initializer(set(tf.global_variables()) - temp))\n",
    "\n",
    "        # Set eval feed_dict and print previous accuracy\n",
    "        train_feed_dict = {input_x: x_train, input_y: y_train, keep_proba_ph: 1.0}\n",
    "        test_feed_dict = {input_x: x_test, input_y: y_test, keep_proba_ph: 1.0}\n",
    "        previous_train_acc = accuracy.eval(feed_dict=train_feed_dict)\n",
    "        previous_test_acc = accuracy.eval(feed_dict=test_feed_dict)\n",
    "        print(f\"Previous: Train/Test ACC: {previous_train_acc:.3f}/{previous_test_acc:.3f}\")\n",
    "        \n",
    "        # Train\n",
    "        for i in range(training_steps):\n",
    "            start = (i * batch_size) % dataset_size\n",
    "            end = min(start + batch_size, dataset_size)\n",
    "            feed_dict={input_x: x_con_train[start:end],\n",
    "                       input_y: y_con_train[start:end],\n",
    "                       keep_proba_ph: keep_proba}\n",
    "            sess.run(train_step, feed_dict=feed_dict)\n",
    "            if i % print_loss_every == 0:\n",
    "                avg_cost = loss.eval(feed_dict=feed_dict)\n",
    "                train_acc = accuracy.eval(feed_dict=train_feed_dict)\n",
    "                test_acc = accuracy.eval(feed_dict=test_feed_dict)\n",
    "                print(f\"Epoch: {i:04d} | AvgCost: {avg_cost:7.4f}\", end=\"\")\n",
    "                print(f\" | Train/Test ACC: {train_acc:.3f}/{test_acc:.3f}\")\n",
    "\n",
    "        # After training, save the sess\n",
    "        # save_path = saver.save(sess, 'model/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**小结：**\n",
    "\n",
    "从上面结果的打印，可以看到，Train ACC 变化不大(因为用的不是训练集的数据)，但 Test ACC 有了显著提升，说明 Online-learning 是有意义的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refrences\n",
    "\n",
    "* [python - In TensorFlow is there any way to just initialize uninitialised variables? - Stack Overflow](http://stackoverflow.com/questions/35164529/in-tensorflow-is-there-any-way-to-just-initialize-uninitialised-variables/37291254)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
